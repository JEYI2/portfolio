{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trj5sVZSJjJa"
      },
      "source": [
        "### 구글 드라이브 마운트"
      ],
      "id": "Trj5sVZSJjJa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL10PEiDMZjX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive/')\n",
        "colab_default_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "working_dir = 'data'\n",
        "os.chdir(colab_default_dir)\n",
        "os.chdir(working_dir)"
      ],
      "id": "AL10PEiDMZjX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6174ad9"
      },
      "source": [
        "### 필요한 라이브러리 불러오기"
      ],
      "id": "d6174ad9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPclVsKdNYUU"
      },
      "outputs": [],
      "source": [
        "!pip install -q finance-datareader\n",
        "!pip install -q mplfinance"
      ],
      "id": "SPclVsKdNYUU"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1a2fa67d"
      },
      "outputs": [],
      "source": [
        "import warnings; warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from collections import Counter\n",
        "import yfinance as yf\n",
        "import FinanceDataReader as fdr\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import sys\n",
        "from mplfinance.original_flavor import candlestick_ohlc\n",
        "import pandas_datareader.data as web\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "1a2fa67d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV_7_UDhJrfZ"
      },
      "source": [
        "### 데이터 불러오기"
      ],
      "id": "rV_7_UDhJrfZ"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fnpbsw4bJtwW"
      },
      "outputs": [],
      "source": [
        "df_01 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202301.csv\", encoding='cp949')\n",
        "df_02 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202302.csv\", encoding='cp949')\n",
        "df_03 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202303.csv\", encoding='cp949')\n",
        "df_04 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202304.csv\", encoding='cp949')\n",
        "df_05 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202305.csv\", encoding='cp949')\n",
        "df_06 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202306.csv\", encoding='cp949')\n",
        "df_07 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202307.csv\", encoding='cp949')\n",
        "df_08 = pd.read_csv(\"./NASDAQ_RSS_IFO/NASDAQ_RSS_IFO_202308.csv\", encoding='cp949')\n",
        "df_tck = pd.read_csv(\"./NASDAQ_FC_STK_IEM_IFO.csv\", encoding='cp949')\n",
        "target = pd.read_csv(\"./NASDAQ_DT_FC_STK_QUT.csv\", encoding='cp949')"
      ],
      "id": "fnpbsw4bJtwW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65bbaa50"
      },
      "source": [
        "### 뉴스 전처리"
      ],
      "id": "65bbaa50"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8b8298df"
      },
      "outputs": [],
      "source": [
        "# 1~8월 뉴스 병합\n",
        "\n",
        "df_01.drop_duplicates(inplace=True)\n",
        "df_01 = df_01.reset_index(drop=True)\n",
        "\n",
        "df_02.drop_duplicates(inplace=True)\n",
        "df_02 = df_02.reset_index(drop=True)\n",
        "\n",
        "df_03.drop_duplicates(inplace=True)\n",
        "df_03 = df_03.reset_index(drop=True)\n",
        "\n",
        "df_04.drop_duplicates(inplace=True)\n",
        "df_04 = df_04.reset_index(drop=True)\n",
        "\n",
        "df_05.drop_duplicates(inplace=True)\n",
        "df_05 = df_05.reset_index(drop=True)\n",
        "\n",
        "df_06.drop_duplicates(inplace=True)\n",
        "df_06 = df_06.reset_index(drop=True)\n",
        "\n",
        "df_07.drop_duplicates(inplace=True)\n",
        "df_07 = df_07.reset_index(drop=True)\n",
        "\n",
        "df_08.drop_duplicates(inplace=True)\n",
        "df_08 = df_08.reset_index(drop=True)\n",
        "\n",
        "df_news = pd.concat([df_01, df_02, df_03, df_04, df_05, df_06, df_07, df_08])\n",
        "df_news = df_news.reset_index(drop=True)"
      ],
      "id": "8b8298df"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7582b02c"
      },
      "outputs": [],
      "source": [
        "# 모든 글자가 대문자인 제목이 있다. 이 경우엔 통째로 소문자로 바꾼다.\n",
        "\n",
        "for i in range(len(df_news)):\n",
        "    if df_news['til_ifo'][i].isupper():\n",
        "        df_news.iloc[i,2] = df_news['til_ifo'][i].lower()"
      ],
      "id": "7582b02c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c6c8c080"
      },
      "outputs": [],
      "source": [
        "# 뉴스 제목과 요약 정보를 합친 열 생성\n",
        "\n",
        "news = []\n",
        "for i in range(len(df_news)):\n",
        "    news.append(df_news['til_ifo'][i] + \".\" + \" \" + df_news['news_smy_ifo'][i])\n",
        "df_news['combined_news'] = news"
      ],
      "id": "c6c8c080"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15353e89"
      },
      "outputs": [],
      "source": [
        "# HTML 태그 제거\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "df_news['combined_news'] = df_news['combined_news'].apply(remove_html_tags)"
      ],
      "id": "15353e89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "477f8565"
      },
      "outputs": [],
      "source": [
        "# 기업명을 티커 코드로 변경\n",
        "\n",
        "df_tck['fc_sec_eng_nm'] = df_tck['fc_sec_eng_nm'].str.rstrip()\n",
        "df_tck['tck_iem_cd'] = df_tck['tck_iem_cd'].str.rstrip()\n",
        "\n",
        "## \"기업명 (티커 코드)\" -> \"티커 코드\"\n",
        "corp_first = []\n",
        "for i in range(len(df_tck)):\n",
        "    corp_first.append(df_tck['fc_sec_eng_nm'][i].split(\" \")[0])\n",
        "\n",
        "for i, row in df_tck.iterrows():\n",
        "    tck = row['tck_iem_cd']\n",
        "    name_first = corp_first[i]\n",
        "    df_news['combined_news'] = df_news['combined_news'].apply(lambda text: re.sub(f'{re.escape(name_first)}.*?{re.escape(f\"({tck})\")}', tck, text) if f\"({tck})\" in text else text)\n",
        "\n",
        "## \"기업명\" -> \"티커 코드\"\n",
        "for i, row in df_tck.iterrows():\n",
        "    corp_name = row['fc_sec_eng_nm']\n",
        "    tck_name = row['tck_iem_cd']\n",
        "    df_news['combined_news'] = df_news['combined_news'].str.replace(corp_name, tck_name)"
      ],
      "id": "477f8565"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e2aa4df"
      },
      "outputs": [],
      "source": [
        "# 괄호로 둘러싸인 부분 모두 제거\n",
        "\n",
        "parentheses = []\n",
        "pattern = r'\\(.*?\\)'\n",
        "\n",
        "for i in range(len(df_news)):\n",
        "    text = df_news['combined_news'][i]\n",
        "    matches = re.findall(pattern, text)\n",
        "    parentheses.extend(matches)\n",
        "\n",
        "for pare in parentheses:\n",
        "    df_news['combined_news'] = df_news['combined_news'].apply(lambda text: text.replace(pare, \"\"))"
      ],
      "id": "7e2aa4df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2585b92"
      },
      "outputs": [],
      "source": [
        "# \".\"이 있는 줄임말을 수정한다.\n",
        "\n",
        "for i in range(len(df_news)):\n",
        "    if \"Inc.\" in df_news['combined_news'][i]:\n",
        "        df_news.iloc[i,8] = df_news['combined_news'][i].replace(\"Inc.\", \"Company\")\n",
        "    elif \"INC.\" in df_news['combined_news'][i]:\n",
        "        df_news.iloc[i,8] = df_news['combined_news'][i].replace(\"INC.\", \"Company\")\n",
        "    elif \"Co.\" in df_news['combined_news'][i]:\n",
        "        df_news.iloc[i,8] = df_news['combined_news'][i].replace(\"Co.\", \"Company\")\n",
        "    elif \"CO.\" in df_news['combined_news'][i]:\n",
        "        df_news.iloc[i,8] = df_news['combined_news'][i].replace(\"CO.\", \"Company\")\n",
        "    elif \"Corp.\" in df_news['combined_news'][i]:\n",
        "        df_news.iloc[i,8] = df_news['combined_news'][i].replace(\"Corp.\", \"Company\")\n",
        "    elif \"CORP.\" in df_news['combined_news'][i]:\n",
        "        df_news.iloc[i,8] = df_news['combined_news'][i].replace(\"CORP.\", \"Company\")"
      ],
      "id": "c2585b92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fb9b3694"
      },
      "outputs": [],
      "source": [
        "# 불용어 제거\n",
        "\n",
        "## nltk가 정의한 불용어(일부 제외)\n",
        "stop_words_list = stopwords.words('english')\n",
        "stop_words_list.remove('above')\n",
        "stop_words_list.remove('below')\n",
        "stop_words_list.remove('up')\n",
        "stop_words_list.remove('down')\n",
        "stop_words_list.remove('over')\n",
        "stop_words_list.remove('under')\n",
        "\n",
        "## 길이가 2 이하이면서 빈도가 2 이하인 단어\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "words = []\n",
        "for i in range(len(df_news)):\n",
        "    text = df_news['combined_news'][i]\n",
        "    tokenized = tokenizer.tokenize(text)\n",
        "    words.extend(tokenized)\n",
        "\n",
        "element_count = Counter(words)\n",
        "for element, count in element_count.items():\n",
        "    if count <= 2:\n",
        "        if len(element) <= 2: stop_words_list.append(element)\n",
        "stop_words_list = set(stop_words_list)\n",
        "\n",
        "## 제거\n",
        "df_news['combined_news'] = df_news['combined_news'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words_list]))"
      ],
      "id": "fb9b3694"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87145965"
      },
      "outputs": [],
      "source": [
        "# 숫자와 특수문자 제거\n",
        "\n",
        "def remove_numbers_and_special_characters(text):\n",
        "    cleaned_text = re.sub(r'[^A-Za-z\\s]', ' ', text)\n",
        "    return cleaned_text\n",
        "\n",
        "df_news['combined_news'] = df_news['combined_news'].apply(remove_numbers_and_special_characters)"
      ],
      "id": "87145965"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe9ce380"
      },
      "outputs": [],
      "source": [
        "# 공백 기준 길이가 1인 단어 제거\n",
        "\n",
        "one_word = [word for i in range(len(df_news))\n",
        "             for word in df_news['combined_news'][i].split() if len(word) == 1]\n",
        "\n",
        "for i in range(len(df_news)):\n",
        "    text = df_news['combined_news'][i]\n",
        "    for word in one_word:\n",
        "        text = re.sub(rf'\\b{re.escape(word)}\\b', '', text)\n",
        "    df_news.iloc[i,8] = text"
      ],
      "id": "fe9ce380"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "858a28e5"
      },
      "outputs": [],
      "source": [
        "# 연속된 공백을 1개의 공백으로 치환\n",
        "\n",
        "def replace_multiple_spaces(text):\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
        "    return cleaned_text\n",
        "\n",
        "df_news['combined_news'] = df_news['combined_news'].apply(replace_multiple_spaces)"
      ],
      "id": "858a28e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78c6face"
      },
      "source": [
        "### 기술지표를 이용하여 긍정/부정/중립 분류"
      ],
      "id": "78c6face"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AT_HUFLoTbjH"
      },
      "outputs": [],
      "source": [
        "# NASDAQ_DT_FC_STK_QUT\n",
        "\n",
        "## 열 이름 재설정\n",
        "target.columns = ['거래일자', '티커종목코드', '종목시가', '종목고가', '종목저가', '종목종가', '누적거래수량', '매도체결합계수량', '매수체결합계수량']\n",
        "\n",
        "## 거래일자를 날짜 형식으로 변환\n",
        "target['거래일자'] = pd.to_datetime(target['거래일자'], format='%Y%m%d')\n",
        "\n",
        "## 거래일자를 인덱스로 설정\n",
        "target.set_index('거래일자', inplace=True)"
      ],
      "id": "AT_HUFLoTbjH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "443f71c6"
      },
      "outputs": [],
      "source": [
        "# 22년 12월 NASDAQ 데이터 불러오기\n",
        "\n",
        "df_krx = fdr.StockListing('NASDAQ')\n",
        "\n",
        "list1 = target['티커종목코드'].unique()\n",
        "df_12_result = pd.DataFrame()\n",
        "\n",
        "for symbol in list1:\n",
        "    try:\n",
        "        df_12 = yf.download(symbol, start='2022-12-01', end='2022-12-31', progress=False)\n",
        "        if not df_12.empty:\n",
        "            df_12['Symbol'] = symbol\n",
        "            df_12_result = pd.concat([df_12_result, df_12])\n",
        "    except: pass\n",
        "\n",
        "df_12_result.columns = ['종목시가','종목고가','종목저가','종목종가','Adj Close','거래량','티커종목코드']\n",
        "target = pd.concat([df_12_result,target])\n",
        "target = target.drop(['Adj Close'], axis = 'columns')"
      ],
      "id": "443f71c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfddace4"
      },
      "outputs": [],
      "source": [
        "# 뉴스 데이터에는 있지만 NASDAQ_DT_FC_STK_QUT 데이터에는 없는 종목 추가\n",
        "\n",
        "news_ticker_list = df_news['tck_iem_cd'].unique()\n",
        "price_ticker_list =target['티커종목코드'].unique()\n",
        "sub_set2 = [x for x in news_ticker_list if x not in price_ticker_list]\n",
        "df_524_result = pd.DataFrame()\n",
        "\n",
        "for symbol in sub_set2:\n",
        "    try:\n",
        "        df_524 = yf.download(symbol, start='2022-12-01', end='2023-08-31', progress=False)\n",
        "        if not df_524.empty:\n",
        "            df_524['티커코드'] = symbol\n",
        "            df_524_result = pd.concat([df_524_result, df_524])\n",
        "    except: pass\n",
        "\n",
        "df_524_result.columns = ['종목시가','종목고가','종목저가','종목종가','Adj Close','거래량','티커종목코드']\n",
        "target = pd.concat([df_524_result, target])\n",
        "target = target.drop(['Adj Close'], axis = 'columns')"
      ],
      "id": "bfddace4"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d04f1af7"
      },
      "outputs": [],
      "source": [
        "# 기술지표 구하기\n",
        "\n",
        "code = list(target['티커종목코드'].unique())\n",
        "\n",
        "## RSI\n",
        "def calculate_RSI(data, code, period=14, column='종목종가'):\n",
        "    results = []\n",
        "\n",
        "    for i in code:\n",
        "        subset = data[data['티커종목코드'] == i]\n",
        "        delta = subset[column].diff(1)\n",
        "        delta = delta.dropna()\n",
        "        up, down = delta.copy(), delta.copy()\n",
        "        up[up < 0] = 0\n",
        "        down[down > 0] = 0\n",
        "        avg_gain = up.rolling(window=period).mean()\n",
        "        avg_loss = abs(down).rolling(window=period).mean()\n",
        "\n",
        "        rs = avg_gain / avg_loss\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        subset['RSI'] = rsi\n",
        "        results.append(subset)\n",
        "\n",
        "    return pd.concat(results)\n",
        "\n",
        "df_RSI = calculate_RSI(target,code, period = 14, column='종목종가')\n",
        "\n",
        "## CMO\n",
        "def CMO(df,code, n_days=20):\n",
        "    results = []\n",
        "\n",
        "    for i in code:\n",
        "        subset = df[df['티커종목코드'] == i]\n",
        "        delta = subset['종목종가'].diff()\n",
        "        dUp , dDown = delta.copy(), delta.copy()\n",
        "        dUp[dUp < 0] = 0\n",
        "        dDown[dDown > 0] = 0\n",
        "        RolUP = dUp.rolling(min_periods = n_days, window = n_days, center = False).mean()\n",
        "        RolDown = dDown.abs().rolling(min_periods = n_days, window = n_days, center = False ).mean()\n",
        "\n",
        "        subset['CMO']= (RolUP-RolDown)/(RolUP+RolDown)  * 100\n",
        "        results.append(subset)\n",
        "\n",
        "    return pd.concat(results)\n",
        "\n",
        "df_CMO = CMO(df_RSI,code,n_days=14)\n",
        "\n",
        "## BOP\n",
        "def BOP(df):\n",
        "    BOP= (df['종목종가']-df['종목시가'])/(df['종목고가'] - df['종목저가'])\n",
        "    df['BOP'] = BOP\n",
        "    return df\n",
        "\n",
        "df_BOP = BOP(df_CMO)\n",
        "\n",
        "## WILLR\n",
        "def calculate_WILLR(group):\n",
        "    low = group['종목저가'].rolling(window=14, min_periods=1).min()\n",
        "    high = group['종목고가'].rolling(window=14, min_periods=1).max()\n",
        "    close = group['종목종가']\n",
        "    WILLR = ((high - close) / (high - low)) * (-100)\n",
        "    group['WILLR'] = WILLR\n",
        "    return group\n",
        "\n",
        "WILLR = target.groupby('티커종목코드').apply(calculate_WILLR)\n",
        "\n",
        "## STOCH_fastk\n",
        "def calculate_stoch_fastk(group):\n",
        "    low = group['종목저가'].rolling(window=14, min_periods=1).min()\n",
        "    high = group['종목고가'].rolling(window=14, min_periods=1).max()\n",
        "    close = group['종목종가']\n",
        "    stoch_fastk = ((close - low) / (high - low)) * 100\n",
        "    group['STOCH_fastk'] = stoch_fastk\n",
        "    return group\n",
        "\n",
        "STOCH_fastk = target.groupby('티커종목코드').apply(calculate_stoch_fastk)"
      ],
      "id": "d04f1af7"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f8aadb13"
      },
      "outputs": [],
      "source": [
        "df_CMO.reset_index(inplace=True)\n",
        "df_CMO.rename(columns={'index': '거래일자'}, inplace=True)\n",
        "WILLR.reset_index(inplace=True)\n",
        "WILLR.rename(columns={'index': '거래일자'}, inplace=True)\n",
        "STOCH_fastk.reset_index(inplace=True)\n",
        "STOCH_fastk.rename(columns={'index': '거래일자'}, inplace=True)\n",
        "\n",
        "merged_df2 = pd.merge(df_CMO, WILLR, on=['거래일자', '티커종목코드'], how='left', suffixes=('', '_WILLR'))\n",
        "merged_df3 = pd.merge(merged_df2, STOCH_fastk, on=['거래일자', '티커종목코드'], how='left', suffixes=('', '_STOCH_fastk'))"
      ],
      "id": "f8aadb13"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "365a3ed7"
      },
      "outputs": [],
      "source": [
        "# RSI 매도/매수/중립 판단\n",
        "merged_df3['RSI_result'] = np.where((0 <= merged_df3['RSI']) & (merged_df3['RSI'] <= 30), 1,\n",
        "                            np.where((70 <= merged_df3['RSI']) & (merged_df3['RSI'] <= 100), 0, 2))\n",
        "\n",
        "# CMO 매도/매수/중립 판단\n",
        "merged_df3['CMO_result'] = np.where((merged_df3['CMO'] <= -40), 1,\n",
        "                            np.where((40<=merged_df3['CMO']), 0, 2))\n",
        "\n",
        "# BOP 매도/매수/중립 판단\n",
        "merged_df3['BOP_result'] = np.where((merged_df3['BOP'] > 0), 1,\n",
        "                            np.where((0> merged_df3['BOP']), 0,2 ))\n",
        "\n",
        "# STOCH_fastk 매도/매수/중립 판단\n",
        "subset = merged_df3[['티커종목코드', 'STOCH_fastk']].copy()\n",
        "subset['yesterday_STOCH_fastk'] = subset.groupby('티커종목코드')['STOCH_fastk'].shift(1)\n",
        "subset['buy_condition'] = (subset['yesterday_STOCH_fastk'] <= 20.0) & (subset['STOCH_fastk'] > subset['yesterday_STOCH_fastk'])\n",
        "subset['sell_condition'] = (subset['yesterday_STOCH_fastk'] >= 80.0) & (subset['STOCH_fastk'] < subset['yesterday_STOCH_fastk'])\n",
        "\n",
        "subset['stock_fastk_result'] = 2\n",
        "subset.loc[subset['buy_condition'], 'stock_fastk_result'] = 1\n",
        "subset.loc[subset['sell_condition'], 'stock_fastk_result'] = 0\n",
        "\n",
        "merged_df3['stock_fastk_result'] = subset['stock_fastk_result']\n",
        "\n",
        "# WILLR 매도/매수/중립 판단\n",
        "subset = merged_df3[['티커종목코드', 'WILLR']].copy()\n",
        "subset['yesterday_WILLR'] = subset.groupby('티커종목코드')['WILLR'].shift(1)\n",
        "subset['buy_condition'] = (subset['yesterday_WILLR'] <= -80.0) & (subset['WILLR'] > subset['yesterday_WILLR'])\n",
        "subset['sell_condition'] = (-20<=subset['yesterday_WILLR']) & (subset['yesterday_WILLR'] <=0) & (subset['WILLR'] < subset['yesterday_WILLR'])\n",
        "\n",
        "subset['WILLR_result'] = 2\n",
        "subset.loc[subset['buy_condition'], 'WILLR_result'] = 1\n",
        "subset.loc[subset['sell_condition'], 'WILLR_result'] = 0\n",
        "\n",
        "merged_df3['WILLR_result'] = subset['WILLR_result']"
      ],
      "id": "365a3ed7"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "95e8ec72"
      },
      "outputs": [],
      "source": [
        "target = merged_df3\n",
        "target = target[['거래일자', '티커종목코드', 'RSI_result', 'CMO_result', 'BOP_result', 'stock_fastk_result', 'WILLR_result']]\n",
        "target['거래일자'] = pd.to_datetime(target['거래일자'], format='%Y-%m-%d')\n",
        "target['거래일자'] = pd.to_datetime(target['거래일자'], format='%Y%m%d')"
      ],
      "id": "95e8ec72"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "39154c39"
      },
      "outputs": [],
      "source": [
        "# 5개의 기술지표를 종합하여 과반수인 것을 채택, 중복이 있다면 중립으로 판단\n",
        "\n",
        "target['result'] = \"\"\n",
        "\n",
        "for i in range(len(target)):\n",
        "    results = []\n",
        "    dup = []\n",
        "\n",
        "    results.append(target['RSI_result'][i])\n",
        "    results.append(target['CMO_result'][i])\n",
        "    results.append(target['BOP_result'][i])\n",
        "    results.append(target['stock_fastk_result'][i])\n",
        "    results.append(target['WILLR_result'][i])\n",
        "\n",
        "    counts = Counter(results)\n",
        "    max_count = max(counts.values())\n",
        "    for element, count in counts.items():\n",
        "        if count == max_count:\n",
        "            dup.append(str(element))\n",
        "\n",
        "    if len(dup) == 1:\n",
        "        majority_element = max(counts, key=counts.get)\n",
        "        target.iloc[i,7] = majority_element\n",
        "\n",
        "    elif len(dup) > 1:\n",
        "        target.iloc[i,7] = 2"
      ],
      "id": "39154c39"
    },
    {
      "cell_type": "code",
      "source": [
        "target = target[~(target['거래일자'].dt.month == 12)]\n",
        "target.drop_duplicates(inplace=True)\n",
        "target = target.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "qHvOVFOgmwTb"
      },
      "id": "qHvOVFOgmwTb",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fc6f9cc8"
      },
      "outputs": [],
      "source": [
        "# 뉴스 발행일 다음 날 관련 종목의 기술지표 정보와 해당 뉴스를 매칭\n",
        "\n",
        "df_news['rgs_dt'] = pd.to_datetime(df_news['rgs_dt'], format='%Y%m%d')\n",
        "df_news['target'] = \"\"\n",
        "\n",
        "df_news['adjusted_date'] = df_news['rgs_dt'] + pd.DateOffset(days=1)\n",
        "merged_df = pd.merge(df_news, target, how='left', left_on=['tck_iem_cd', 'adjusted_date'], right_on=['티커종목코드', '거래일자'])\n",
        "\n",
        "df_news['target'] = merged_df['result'].fillna(\"\").values\n",
        "\n",
        "df_news.drop('adjusted_date', axis=1, inplace=True)\n",
        "if '거래일자' in df_news.columns:\n",
        "    df_news.drop('거래일자', axis=1, inplace=True)\n",
        "\n",
        "df_news = df_news[df_news['target'] != '']\n",
        "df_news['target'] = df_news['target'].astype(int)"
      ],
      "id": "fc6f9cc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d11b250e"
      },
      "source": [
        "### 모델 훈련 및 평가"
      ],
      "id": "d11b250e"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5ef7c0d0"
      },
      "outputs": [],
      "source": [
        "# 중립인 것은 제외\n",
        "df_news = df_news[df_news['target'] != 2]\n",
        "\n",
        "# 텍스트 토큰화\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df_news['combined_news'])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# 텍스트를 정수 시퀀스로 변환하고 패딩\n",
        "input_sequences = tokenizer.texts_to_sequences(df_news['combined_news'])\n",
        "max_sequence_length = max(len(sequence) for sequence in input_sequences)\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# 타켓 데이터\n",
        "labels = np.array(df_news['target'])\n",
        "\n",
        "# Embedding 차원 정의\n",
        "embedding_dim = 50\n",
        "\n",
        "# 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, embedding_dim, input_length=max_sequence_length))\n",
        "model.add(GRU(dropout=0.5, units=100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "id": "5ef7c0d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1affd527"
      },
      "outputs": [],
      "source": [
        "# 훈련 데이터와 검증 데이터 분리(7:3)\n",
        "train_input, val_input, train_target, val_target = train_test_split(padded_sequences, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(train_input, train_target, epochs=6)\n",
        "\n",
        "# 모델 평가\n",
        "acc = model.evaluate(val_input, val_target)\n",
        "print(\"Test Accuracy:\", acc[1])\n",
        "print(\"Test Loss:\",acc[0])"
      ],
      "id": "1affd527"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}